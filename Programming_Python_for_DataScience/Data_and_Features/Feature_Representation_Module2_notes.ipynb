{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Textual Categorical-Features : Ordinal and Nominal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have a categorical feature, how you represent it in your dataset will depend on if it's ordinal or nominal categorical feature. In the case of **ordinals**, you should create a **mapping** of increasing integers to each possible unique value of the feature. Any entries not found in your designated categories list will be mapped to -1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  satisfaction\n",
      "0          NaN\n",
      "1        Happy\n",
      "2      Unhappy\n",
      "3      Neutral\n",
      "satisfaction    category\n",
      "dtype: object\n",
      "\n",
      "   satisfaction\n",
      "0            -1\n",
      "1             3\n",
      "2             1\n",
      "3             2\n",
      "satisfaction    int8\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files (x86)\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: FutureWarning: specifying 'categories' or 'ordered' in .astype() is deprecated; pass a CategoricalDtype instead\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# creating a dummy dataset\n",
    "ordered_satisfaction = ['Very Unhappy', 'Unhappy', 'Neutral', 'Happy', 'Very Happy']\n",
    "\n",
    "# sample datafram with some results. 'Mad' is not part of the ordered_satisfaction:\n",
    "df = pd.DataFrame({'satisfaction':['Mad', 'Happy', 'Unhappy', 'Neutral']})\n",
    "\n",
    "# using astype() to convert the dataframe into a category that is ordered by ordered_satisfaction\n",
    "df.satisfaction = df.satisfaction.astype(dtype=\"category\", ordered=True, categories=ordered_satisfaction)\n",
    "\n",
    "print(df) # the NaN is because 'Mad' is not a category\n",
    "print(df.dtypes) # is a category\n",
    "print()\n",
    "\n",
    "# changing the dtype to numeric with cat.codes\n",
    "df.satisfaction = df.satisfaction.cat.codes\n",
    "print(df)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, if your feature is **nominal** and therefore **lacking any inherent numeric ordering**, then you have two options. The first is you can encoded the fature similar as you did above. This would be a fast-and-dirty approach. While you're just getting accustomed to your dataset and taking it for its first run through your data analysis pipeline, this method might be the most convenient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'vertebrates':['Bird','Bird','Mammal','Fish','Amphibian','Reptile','Mammal']})\n",
    "\n",
    "# this time we do not use the ordered=True in astype(), so each new sample type will receive a new number\n",
    "df['vertebrates_numeric'] = df.vertebrates.astype(dtype=\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vertebrates</th>\n",
       "      <th>vertebrates_numeric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bird</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bird</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mammal</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fish</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amphibian</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Reptile</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mammal</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  vertebrates  vertebrates_numeric\n",
       "0        Bird                    1\n",
       "1        Bird                    1\n",
       "2      Mammal                    3\n",
       "3        Fish                    2\n",
       "4   Amphibian                    0\n",
       "5     Reptile                    4\n",
       "6      Mammal                    3"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how this time, **ordered=True was not passed in**, nor was a specific ordering listed. Because of this, Pandas automatically encodes your nominal entries in alphabetical order. This approach is fine for getting your feet wet; but the issue it has is that it introduces an ordering to a categorical list of items that inherently has none. This may or may not cause problems for you in the future. If you aren't getting the results you hoped for, or even if you are getting the results you desired but would like to further increase the result accuracy, then a more precise encoding approach would be to separate the distinct values out into individual boolean features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vertebrates_Amphibian</th>\n",
       "      <th>vertebrates_Bird</th>\n",
       "      <th>vertebrates_Fish</th>\n",
       "      <th>vertebrates_Mammal</th>\n",
       "      <th>vertebrates_Reptile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vertebrates_Amphibian  vertebrates_Bird  vertebrates_Fish  \\\n",
       "0                      0                 1                 0   \n",
       "1                      0                 1                 0   \n",
       "2                      0                 0                 0   \n",
       "3                      0                 0                 1   \n",
       "4                      1                 0                 0   \n",
       "5                      0                 0                 0   \n",
       "6                      0                 0                 0   \n",
       "\n",
       "   vertebrates_Mammal  vertebrates_Reptile  \n",
       "0                   0                    0  \n",
       "1                   0                    0  \n",
       "2                   1                    0  \n",
       "3                   0                    0  \n",
       "4                   0                    0  \n",
       "5                   0                    1  \n",
       "6                   1                    0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'vertebrates':['Bird','Bird','Mammal','Fish','Amphibian','Reptile','Mammal']})\n",
    "\n",
    "# get_dummies() convert a categorical variable into dummy/indicator variable\n",
    "# create a column where the variable is 1 if exist or 0 if don't.\n",
    "df = pd.get_dummies(df,columns=['vertebrates'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These newly created features are called boolean features because the only values they can contain are either 0 for non-inclusion, or 1 for inclusion. Pandas .get_dummies() method allows you to completely replace a single, nominal feature with multiple boolean indicator features. This method is quite powerful and has many configurable options, including the ability to return a SparseDataFrame, and other prefixing options. Its benefit over Method #1 above is that no erroneous ordering is introduced into your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pure Textual Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are trying to \"featurize\" a body of text such as a webpage, a tweet, a passage from a newspaper, an entire book, or a PDF document, creating a corpus of words and counting their frequency is an extremely powerful encoding tool. This is also known as the **Bag of Words model**, implemented with the **CountVectorizer() method in SciKit-Learn**. Even though the grammar of your sentences and their word-order are completely discarded, this model has accomplished some pretty amazing things, such as being able to correctly identifying J.K. Rowling's writing from a blind line up of authors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CountVectorizer:\n",
    "Convert a collection of text documents to a matrix of token counts.\n",
    "\n",
    "This implementation produces a sparse representation of the counts using scipy.sparse.csr_matrix.\n",
    "\n",
    "If you do not provide an a-priori dictionary and you do not use an analyzer that does some kind of feature selection then the number of features will be equal to the vocabulary size found by analyzing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\"Authman ran faster than Harry because he is an athlete.\",\"Authman and Harry ran faster and faster.\", \"W00t.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x12 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 16 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow = CountVectorizer()\n",
    "X = bow.fit_transform(corpus) # this produces a Sparse Matrix. Pandas only save the the non zero values.\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['an',\n",
       " 'and',\n",
       " 'athlete',\n",
       " 'authman',\n",
       " 'because',\n",
       " 'faster',\n",
       " 'harry',\n",
       " 'he',\n",
       " 'is',\n",
       " 'ran',\n",
       " 'than',\n",
       " 'w00t']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
       "       [0, 2, 0, 1, 0, 2, 1, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can see the sparse matrix with:\n",
    "X.toarray()\n",
    "# the word 'an' is only once used in the first sentence, the word 'and' is twice used in the second sentence ... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "\n",
    "Notice that X is not stored as a regular [n_samples, n_features] dataframe that you've become accustomed to. Rather, it is a SciPy compressed, sparse, row matrix. SciPy is a library of mathematical algorithms and convenience functions that further extend NumPy. The reason X is now a sparse matrix instead of a classical dataframe is because even with this small example of two sentences, 11 features were created. The average English speaker knows around 8000 unique words. If each sentence were an 8000-sized vector sample in your dataframe, consisting mostly of 0's, it would be a poor use of memory.\n",
    "\n",
    "To avoid this, SciPy implements sparse matrices as Python dictionaries: only the keys that have a value get stored, and everything else is assumed to be empty. You can always convert it back to a regular Python list by using the .toarray() method, but this converts it to a dense array, which might not be desirable due to memory usage reasons. To use your compressed, sparse, row matrix in Pandas, you're going to want to convert it to a Pandas SparseDataFrame. More notes on that in the Dive Deeper section.\n",
    "\n",
    "The bag of words model has other configurable parameters you can tune, such as having it pay attention to the order of words in your text. In such implementations, pairs or tuples of successive words are used to build the corpus instead of individual words:\n",
    "\n",
    "```python\n",
    "bow.get_feature_names()\n",
    "['authman ran', 'ran faster', 'faster than', 'than harry', 'harry because', 'because he', 'he is', 'is an', 'an athlete', 'authman and', 'and harry', 'harry ran', 'faster and', 'and faster'] ```\n",
    "\n",
    "Another configurable parameter is to have CountVectorizer() use frequencies instead of counts. This is useful when you have documents of different lengths. Words show up more often in the larger document than the shorter one simply based on it's length; so normalizing the word count by the total number of words in each document create a more fair 'direct' comparison between the two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Feature Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files (x86)\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = misc.imread('cat.jpg') # ndarray\n",
    "type(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 4000, 3)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape  # 3 color channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.dtype # integers with 8bits - they range from 0 to 255 (for each color channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(750, 1000, 3)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = img[::2,::2] # always skiping one pixel, because the pixels in pairs are basically the same color.\n",
    "img.shape # shrink the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = (img/225.).reshape(-1,3) # red, green, blue channels are normalized to 0-1 and reshaping to a 1D array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "red = img[:,0]\n",
    "green = img[:,1]\n",
    "blue = img[:,2]\n",
    "\n",
    "grey = 0.299*red + 0.587*green + 0.114*blue  # convert the image into grayscales. Luminance Formula\n",
    "\n",
    "# we can do machine learning with gray!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Feature Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io.wavfile as wavfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate, audio_data = wavfile.read('sexta.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48000"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_rate  # 348000 kilohertz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0],\n",
       "       [ 0,  0],\n",
       "       [ 0,  0],\n",
       "       ...,\n",
       "       [57, 55],\n",
       "       [51, 49],\n",
       "       [45, 45]], dtype=int16)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_data  # we can do machine learning with the audio"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
